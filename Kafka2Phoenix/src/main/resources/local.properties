# 运行环境
product.or.test=test

# kerberos配置
kerberos.principal=test@HADOOP.COM
keytab.file=D:/workdata/test-keytab/test.keytab
java.security.auth.login.config=D:/workdata/test-keytab/kafka_client_jaas.conf
java.security.krb5.conf=D:/workdata/test-keytab/krb5.conf

# kafka连接
bootstrap.servers=192.168.100.23:6667,192.168.100.24:6667,192.168.100.25:6667
# groupid
group.id=test_202110_test
# jaas参数（yarn模式使用）
sasl.jaas.config=com.sun.security.auth.module.Krb5LoginModule required useKeyTab=true useTicketCache=false storeKey=true keyTab="D:/workdata/test-keytab/test.keytab" principal="test@HADOOP.COM";

# 实时流数据拉取间隔时间
dual.time=30

# hive认证账号
hive.krb.principal=dianke@HDPCLUSTER.COM
sparkSession.debug.maxToStringFields=2000
duration.length=300

# zookeeper集群
zookeeper.connect=192.168.100.23:2181,192.168.100.24:2181,192.168.100.25:2181

# checkpoint路径
spark.checkpointPath=/data/huaruan

# 默认启动业务
which.app.to.run=GpsVehicleTraffic
log.level=INFO
# kafka服务配置
auto.offset.reset=latest
spark.default.parallelism=3
# shuffler操作并行度
spark.sql.shuffle.partitions=3
# 运行模式
spark.scheduler.mode=FAIR
# 序列化
spark.serializer=org.apache.spark.serializer.KryoSerializer
# 额外的java参数
spark.executor.extraJavaOptions=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps

# phoenix参数
phoenix.driver=org.apache.phoenix.jdbc.PhoenixDriver
phoenix.url=jdbc:phoenix:192.168.100.23,192.168.100.24,192.168.100.25:2181:/hbase-secure:/test@HADOOP.COM